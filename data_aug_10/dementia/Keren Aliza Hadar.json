{
  "name": "Keren Aliza Hadar",
  "start_deterioration_age": 72,
  "stories": [
    {
      "age": 60,
      "story": "The project that continues to reverberate in my mind began with a deceptively simple municipal dataset: hospitalization counts, stratified by neighborhood, age band, and week. The city’s public health office wanted a predictive dashboard for resource allocation—ostensibly routine. Yet an exploratory pass revealed volatile sparsity at the neighborhood granularity, with variance structures that would punish naive aggregation. I recall the first whiteboard session: three overlapping problem layers—signal stabilization, ethical interpretability, and policy latency. We implemented a hierarchical Bayesian model to borrow statistical strength across adjacent districts, embedding structured priors reflecting transit-linked adjacency rather than arbitrary geography. Midway through, a junior analyst suggested collapsing two demographic categories to ‘simplify.’ It triggered a design conversation about how categorical compression can erase disparity signals under the guise of noise reduction. I wrote a memo—part technical, part ethical—arguing that model parsimony cannot outrank visibility for vulnerable subpopulations. We paired the forecasting core with an uncertainty ribbon and a narrative annotation system that surfaced cautionary explanations whenever intervals overlapped or data density fell below threshold. The pivotal moment was a review meeting where a policymaker leaned on a single-week spike; our system interjected a contextual panel: ‘High volatility zone—projection provisional.’ The meeting’s tempo shifted from premature decisiveness to reflective questioning. That shift was the success. It proved we could embed epistemic humility directly into interface affordances, steering decisions away from overconfident misallocation. In the post-mortem I emphasized that ethical alignment wasn’t a wrapper tacked on after modeling; it was an architectural choice shaping priors, aggregation boundaries, and interaction design. That integration remains my quiet benchmark for responsible data science practice." 
    },
    {
      "age": 63,
      "story": "I often revisit a civic health forecasting tool we built—ostensibly a standard hospitalization projection dashboard. Data fragmentation by neighborhood created sparse, noisy weekly slices. Instead of resorting to aggressive smoothing that would have hidden meaningful local signals, we chose a hierarchical Bayesian structure that allowed sharing of information across transit-connected zones rather than blunt geographic adjacency. A junior teammate proposed merging demographic strata to ‘stabilize.’ That suggestion became a teaching moment: collapsing categories can mute inequities while claiming statistical cleanliness. We retained granularity and exposed uncertainty plainly—interval bands plus contextual flags when data density was weak. The product’s defining moment was when a decision-maker fixated on a single spike; the interface surfaced an automated caution note, reframing the discussion around confidence levels. The lesson I carried forward is that ethical design lives inside model architecture and interface semantics, not in a late-stage disclaimer. Building the guardrails early changed the conversation from performance theater to informed stewardship." 
    },
    {
      "age": 66,
      "story": "There was a municipal health dashboard we delivered: forecasting hospital load by neighborhood. Data were thin in several districts, and naive aggregation would have flattened important disparities. We used a hierarchical model so smaller areas could ‘borrow’ structure from related zones without erasing their identity. Someone suggested merging demographic groups, and it led to a brief but valuable debate about how simplification can conceal vulnerable patterns. We kept the detail, paired forecasts with clear uncertainty bands, and added small automated notes when volatility made a point unstable. In a review, that prompt stopped a premature resource shift. What stays with me is how early architectural decisions—priors, grouping, annotations—quietly enforced better ethics without scolding users. It felt like a blueprint for responsible practice." 
    },
    {
      "age": 69,
      "story": "I think about a city project predicting hospital use. The data were patchy; some neighborhoods had thin counts. We chose a layered model so sparse places could lean on related areas a bit. A teammate wanted to merge groups to reduce noise; we decided not to, to keep visibility for smaller populations. We showed uncertainty bands and short notes when numbers were shaky. In one meeting, that note prevented an overreaction to a jump. It reminded me that building caution into the design early matters more than a warning slide later." 
    },
    {
      "age": 72,
      "story": "There was that health dashboard—hospital forecasts by area. Some places had little data. We used a model that shared strength but kept each area separate. We kept groups unmerged so we didn’t hide smaller ones. The chart showed ranges, and little messages appeared when a value was unstable. In a meeting those messages slowed a quick decision. I liked that. The careful parts were in the build, not added after." 
    },
    {
      "age": 75,
      "story": "I remember a city dashboard. Hospital numbers, by areas. Data thin in spots. We let areas share a bit but stay apart. Didn’t merge groups. Showed ranges and small notes when not steady. One note stopped a rushed move. That’s the piece I keep: design holding people back from jumping too fast." 
    }
  ]
}
